diff --git a/.vscode/launch.json b/.vscode/launch.json
index 8271fc8..2bb9916 100644
--- a/.vscode/launch.json
+++ b/.vscode/launch.json
@@ -405,7 +405,7 @@
                 // "--lam_mmd", "10.0",
                 "--seed", "1612",
                 "-gc", "0.001",
-                // "--eu2rwa"
+                "--eu2rwa"
                 // "--lam_raw", "0.3.",
                 // "--occupancymodel",
                 // "--stochasticWA"
@@ -425,7 +425,7 @@
                 "-e",
                 "200",
                 "-b",
-                "128",
+                "32",
                 "-lr", 
                 "1e-5", 
                 "--model", "BoostUNet",  
@@ -435,8 +435,8 @@
                 "-la",
                 "1.0",
                 // "0.1",
-                "-dw","4",
-                "-dw2","1",
+                "-dw","2",
+                "-dw2","4",
                 "-S2",
                 "-S1",
                 // "-NIR",
@@ -444,8 +444,8 @@
                 "16",
                 "-rse",
                 "-treg",
-                "pricp2",
-                // "rwa",
+                // "pricp2",
+                "rwa",
                 // "-ladv", "0.01",
                 "-exZH",
                 "--val", "1",
@@ -464,8 +464,11 @@
                 // "--lam_mmd", "10.0",
                 "--seed", "1612",
                 "-gc", "0.001",
-                // "--CyCADA",
+                "--CyCADA",
                 "--CyCADASourcecheckpoint", "/scratch2/metzgern/HAC/POMELOv2_results/So2Sat/experiment_905_626/best_model.pth",
+                "--lam_selfsupervised_consistency", "10",
+                "--lam_targetconsistency", "10"
+                
                 // "--eu2rwa" 
             ]
         },
diff --git a/arguments/__pycache__/train.cpython-310.pyc b/arguments/__pycache__/train.cpython-310.pyc
index 44a3b30..8538caa 100644
Binary files a/arguments/__pycache__/train.cpython-310.pyc and b/arguments/__pycache__/train.cpython-310.pyc differ
diff --git a/arguments/train.py b/arguments/train.py
index 06c3a8c..25f87dc 100644
--- a/arguments/train.py
+++ b/arguments/train.py
@@ -52,6 +52,8 @@ parser.add_argument("-clasif", "--classifier", default="v8", help="")
 parser.add_argument("-CyCADA", "--CyCADA", action='store_true', help="")
 parser.add_argument("-CyCADAGcheck", "--CyCADAGANcheckpoint", type=str, default="eu2rwa_cycleganFreeze", help="")
 parser.add_argument("-CyCADAScheck", "--CyCADASourcecheckpoint", type=str, default="", help="")
+parser.add_argument("-ltc", "--lam_targetconsistency", help='', type=float, default=1.0)
+parser.add_argument("-lssc", "--lam_selfsupervised_consistency", help='', type=float, default=1.0)
 parser.add_argument("-e2rwa", "--eu2rwa", action='store_true', help="")
 
 parser.add_argument("-head", "--head", default="v1", help="")
diff --git a/data/PopulationDataset_target.py b/data/PopulationDataset_target.py
index 1631ed9..4a6f49e 100644
--- a/data/PopulationDataset_target.py
+++ b/data/PopulationDataset_target.py
@@ -443,6 +443,7 @@ class Population_Dataset_target(Dataset):
         census = pd.read_csv(census_file)
 
         if gpu_mode:
+            # pred = pred.to(torch.float32).cuda()
             pred = pred.cuda()
             boundary = boundary.cuda()
             census_pred = torch.zeros(len(census), dtype=torch.float32).cuda()
@@ -452,9 +453,10 @@ class Population_Dataset_target(Dataset):
             for i, (cidx,bbox) in enumerate(zip(census["idx"], census["bbox"])):
             # for i, (cidx,bbox) in tqdm(enumerate(zip(census["idx"], census["bbox"]))):
                 xmin, xmax, ymin, ymax = tuple(map(int, bbox.strip('()').strip('[]').split(',')))
-                census_pred[i] = pred[xmin:xmax, ymin:ymax][boundary[xmin:xmax, ymin:ymax]==cidx].sum()
+                census_pred[i] = pred[xmin:xmax, ymin:ymax][boundary[xmin:xmax, ymin:ymax]==cidx].to(torch.float32).sum()
 
         else:
+            pred = pred.to(torch.float32)
             census_pred = torch.zeros(len(census), dtype=torch.float32)
 
             # iterate over census regions and get totals
diff --git a/data/__pycache__/PopulationDataset_target.cpython-310.pyc b/data/__pycache__/PopulationDataset_target.cpython-310.pyc
index bb2a8a2..ec18dd4 100644
Binary files a/data/__pycache__/PopulationDataset_target.cpython-310.pyc and b/data/__pycache__/PopulationDataset_target.cpython-310.pyc differ
diff --git a/data/__pycache__/So2Sat.cpython-310.pyc b/data/__pycache__/So2Sat.cpython-310.pyc
index bd45e05..b218b3c 100644
Binary files a/data/__pycache__/So2Sat.cpython-310.pyc and b/data/__pycache__/So2Sat.cpython-310.pyc differ
diff --git a/model/cycleGAN/models/cycle_gan_model.py b/model/cycleGAN/models/cycle_gan_model.py
index b5f0c23..92684e1 100644
--- a/model/cycleGAN/models/cycle_gan_model.py
+++ b/model/cycleGAN/models/cycle_gan_model.py
@@ -5,6 +5,10 @@ from model.cycleGAN.util.image_pool import ImagePool
 from .base_model import BaseModel
 from . import networks
 
+from utils.plot import plot_2dmatrix
+from utils.losses import get_loss, LogL1Loss
+from torchvision import transforms
+
 
 class CycleGANModel(BaseModel):
     """
@@ -68,6 +72,9 @@ class CycleGANModel(BaseModel):
         else:  # during test time, only load Gs
             self.model_names = ['G_A', 'G_B']
 
+        self.normalize = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  
+        self.unnormalize  = transforms.Normalize( mean=[-1, -1, -1], std=[2, 2, 2] )   
+
         # define networks (both Generators and discriminators)
         # The naming is different from those used in the paper.
         # Code (vs. paper): G_A (G), G_B (F), D_A (D_Y), D_B (D_X)
@@ -91,6 +98,9 @@ class CycleGANModel(BaseModel):
             self.criterionGAN = networks.GANLoss(opt.gan_mode).to(self.device)  # define GAN loss.
             self.criterionCycle = torch.nn.L1Loss()
             self.criterionIdt = torch.nn.L1Loss()
+            # self.criterionFakePop = torch.nn.L1Loss()
+            self.criterionFakePop = LogL1Loss()
+            # self.criterionFakePop = torch.nn.L1Loss()
             # initialize optimizers; schedulers will be automatically created by function <BaseModel.setup>.
             self.optimizer_G = torch.optim.Adam(itertools.chain(self.netG_A.parameters(), self.netG_B.parameters()), lr=opt.lr, betas=(opt.beta1, 0.999))
             self.optimizer_D = torch.optim.Adam(itertools.chain(self.netD_A.parameters(), self.netD_B.parameters()), lr=opt.lr, betas=(opt.beta1, 0.999))
@@ -149,7 +159,7 @@ class CycleGANModel(BaseModel):
         fake_A = self.fake_A_pool.query(self.fake_A)
         self.loss_D_B = self.backward_D_basic(self.netD_B, self.real_A, fake_A)
 
-    def backward_G(self):
+    def backward_G(self, gt=None): 
         """Calculate the loss for generators G_A and G_B"""
         lambda_idt = self.opt.lambda_identity
         lambda_A = self.opt.lambda_A
@@ -175,21 +185,71 @@ class CycleGANModel(BaseModel):
         # Backward cycle loss || G_A(G_B(B)) - B||
         self.loss_cycle_B = self.criterionCycle(self.rec_B, self.real_B) * lambda_B
         # combined loss and calculate gradients
-        self.loss_G = self.loss_G_A + self.loss_G_B + self.loss_cycle_A + self.loss_cycle_B + self.loss_idt_A + self.loss_idt_B
-        self.loss_G.backward()
-
-    def optimize_parameters(self):
+        self.loss_G = self.loss_G_A + self.loss_G_B + self.loss_cycle_A + self.loss_cycle_B + self.loss_idt_A + self.loss_idt_A
+        
+        #TODO: may need to retain_graph=True here, or just add the consistency loss to the loss_G
+        if gt is not None:
+            self.convert_preprocessing()
+            self.calculate_consistency_loss(gt)
+            self.loss_G += self.loss_fake_B_pop * self.opt.lambda_popB
+            self.loss_G += self.loss_fake_B_consistency * self.opt.lambda_consistencyB
+            self.loss_G += self.loss_real_B_consistency * self.opt.lambda_consistencyB
+        
+        self.loss_G.backward(retain_graph=True)
+
+    def optimize_parameters(self, gt=None):
         """Calculate losses, gradients, and update network weights; called in every training iteration"""
         # forward
         self.forward()      # compute fake images and reconstruction images.
         # G_A and G_B
         self.set_requires_grad([self.netD_A, self.netD_B], False)  # Ds require no gradients when optimizing Gs
         self.optimizer_G.zero_grad()  # set G_A and G_B's gradients to zero
-        self.backward_G()             # calculate gradients for G_A and G_B
+        self.backward_G(gt=gt)             # calculate gradients for G_A and G_B
         self.optimizer_G.step()       # update G_A and G_B's weights
         # D_A and D_B
-        self.set_requires_grad([self.netD_A, self.netD_B], True)
+        self.set_requires_grad([self.netD_A, self.netD_B], True) # Ds require gradients when optimizing Ds
         self.optimizer_D.zero_grad()   # set D_A and D_B's gradients to zero
         self.backward_D_A()      # calculate gradients for D_A
         self.backward_D_B()      # calculate graidents for D_B
         self.optimizer_D.step()  # update D_A and D_B's weights
+
+    def convert_preprocessing(self):
+
+        raw_real_A = self.unnormalize(self.real_A)*4000
+        real_A_prep = ((raw_real_A.permute((0,2,3,1)) - self.dataset_stats["sen2spring"]['mean'].cuda() ) / self.dataset_stats["sen2spring"]['std'].cuda()).permute((0,3,1,2))
+        self.real_A_prep = torch.cat((real_A_prep, self.S1_A), dim=1)
+
+        raw_fake_A = self.unnormalize(self.fake_A)*4000
+        fake_A_prep = ((raw_fake_A.permute((0,2,3,1)) - self.dataset_stats["sen2spring"]['mean'].cuda() ) / self.dataset_stats["sen2spring"]['std'].cuda()).permute((0,3,1,2))
+        self.fake_A_prep = torch.cat((fake_A_prep, self.S1_A), dim=1)
+
+        raw_real_B = self.unnormalize(self.real_B)*4000
+        real_B_prep = ((raw_real_B.permute((0,2,3,1)) - self.dataset_stats["sen2spring"]['mean'].cuda() ) / self.dataset_stats["sen2spring"]['std'].cuda()).permute((0,3,1,2))
+        self.real_B_prep = torch.cat((real_B_prep, self.S1_B), dim=1)
+
+        raw_fake_B = self.unnormalize(self.fake_B)*4000
+        fake_B_prep = ((raw_fake_B.permute((0,2,3,1)) - self.dataset_stats["sen2spring"]['mean'].cuda() ) / self.dataset_stats["sen2spring"]['std'].cuda()).permute((0,3,1,2))
+        self.fake_B_prep = torch.cat((fake_B_prep, self.S1_B), dim=1)
+
+
+    def calculate_consistency_loss(self, gt, feature_loss = False):
+        feature_loss = False
+
+        with torch.no_grad():
+            self.real_A_output = self.sourcepopmodel({"input": self.real_A_prep}, train=True, alpha=0, return_features=False) # noisy label
+            self.fake_A_output = self.sourcepopmodel({"input": self.fake_A_prep}, train=True, alpha=0, return_features=False)
+            self.real_B_output = self.sourcepopmodel({"input": self.real_B_prep}, train=True, alpha=0, return_features=False)
+            self.fake_B_output = self.sourcepopmodel({"input": self.fake_B_prep}, train=True, alpha=0, return_features=feature_loss)
+
+        if "decoder_features" in self.fake_B_output.keys():
+            self.fake_B_features = self.fake_B_output["decoder_features"]
+
+        self.real_A_output["popcount"] = self.real_A_output["popcount"].detach()
+        self.real_A_output["popdensemap"] = self.real_A_output["popdensemap"].detach()
+
+        self.loss_fake_B_pop, _ = get_loss(self.real_A_output, {"y":gt, "source": torch.ones_like(gt, dtype=bool)}, loss=["log_l1_aug_loss"], lam=[1.0], merge_aug=2, tag="fakeBsource")
+        self.loss_fake_B_consistency = self.criterionFakePop(self.real_A_output["popdensemap"], self.fake_B_output["popdensemap"])
+        self.loss_real_B_consistency = self.criterionFakePop(self.real_B_output["popdensemap"], self.fake_A_output["popdensemap"])
+
+
+
diff --git a/run_train.py b/run_train.py
index b055976..d31b53d 100644
--- a/run_train.py
+++ b/run_train.py
@@ -46,6 +46,9 @@ from utils.constants import inference_patch_size as ips
 from utils.utils import Namespace
 
 from model.cycleGAN.models import create_model
+from model.cycleGAN.util.visualizer import Visualizer
+
+torch.autograd.set_detect_anomaly(True)
 
 import nvidia_smi
 nvidia_smi.nvmlInit()
@@ -57,7 +60,7 @@ class Trainer:
         self.args = args
 
         # check if we are doing domain adaptation or not
-        if args.adversarial or args.CORAL or args.MMD:
+        if args.adversarial or args.CORAL or args.MMD or self.args.CyCADA:
             self.args.da = True
         else:
             self.args.da = False
@@ -76,6 +79,19 @@ class Trainer:
         # define input channels based on the number of input modalities
         # input_channels = args.Sentinel1*2  + args.NIR*1 + args.Sentinel2*3 + args.VIIRS*1
         
+            
+        # define architecture
+        if args.model in model_dict:
+            model_kwargs = get_model_kwargs(args, args.model)
+            self.model = model_dict[args.model](**model_kwargs).cuda()
+        else:
+            raise ValueError(f"Unknown model: {args.model}")
+        
+        if args.model in ["BoostUNet"]:
+            self.boosted = True
+        else:
+            self.boosted = False
+
         if args.CyCADA:
             # load the pretrained cycleGAN model 
             opt = Namespace(model="cycle_gan", name=args.CyCADAGANcheckpoint, input_nc=3, output_nc=3, ngf=64, ndf=64,
@@ -83,34 +99,32 @@ class Trainer:
                             no_dropout=True, init_type="normal", init_gain=0.02, epoch="latest", load_iter=0, isTrain=True, gpu_ids=[0],
                             preprocess=None, continue_train=True, gan_mode="lsgan", pool_size=50, beta1=0.5, lambda_identity=0.5, lr=0.0002, 
                             dataset_mode="unaligned", verbose=False, lr_policy="linear", epoch_count=1, n_epochs=args.num_epochs, n_epochs_decay=args.num_epochs,
-                            # model_suffix="_A", 
+                            lambda_A=10.0, lambda_B=10.0, lambda_consistencyB=10000.0, lambda_popB=100.0,
+                            display_id=1, no_html=False, display_port=8097,
+                            use_wandb=True, display_ncols=4,  wandb_project_name="CycleGAN-and-pix2pix", display_winsize=100, display_env="main", display_server="http://localhost",
+                            # model_suffix="_A",
                             checkpoints_dir="/scratch2/metzgern/HAC/code/CycleGANAugs/pytorch-CycleGAN-and-pix2pix/checkpoints/" )
             self.CyCADAmodel = create_model(opt)      # create a model given opt.model and other options
             self.CyCADAmodel.setup(opt)               # regular setup: load and print networks; create schedulers
+            self.normalize = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) 
 
             # load the pretrained population model
             if args.model in model_dict:
+                # get the source model and load weights
                 model_kwargs = get_model_kwargs(args, args.model)
-                self.sourcemodel = model_dict[args.model](**model_kwargs).cuda()
-                # load weights
-                self.sourcemodel.load_state_dict(torch.load(args.CyCADASourcecheckpoint)['model'])
+                self.CyCADAmodel.sourcepopmodel = model_dict[args.model](**model_kwargs).cuda()
+                self.CyCADAmodel.sourcepopmodel.load_state_dict(torch.load(args.CyCADASourcecheckpoint)['model'])
+                self.CyCADAmodel.sourcepopmodel.eval()
+
+                visualizer = Visualizer(opt)   # create a visualizer that display/save images and plots
+                total_iters = 0                # the total number of training iterations
+
+                # initialize the target model
+                self.model.load_state_dict(torch.load(args.CyCADASourcecheckpoint)['model'])
                 
             else:
                 raise ValueError(f"Unknown model: {args.model}")
             
-
-        # define architecture
-        if args.model in model_dict:
-            model_kwargs = get_model_kwargs(args, args.model)
-            self.model = model_dict[args.model](**model_kwargs).cuda()
-        else:
-            raise ValueError(f"Unknown model: {args.model}")
-        
-        if args.model in ["BoostUNet"]:
-            self.boosted = True
-        else:
-            self.boosted = False
-
         # number of params
         args.pytorch_total_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
         print("Model", args.model, "; #Params:", args.pytorch_total_params)
@@ -241,14 +255,28 @@ class Trainer:
 
                 # forward pass
                 sample = to_cuda_inplace(sample)
-                sample = apply_transformations_and_normalize(sample, self.data_transform, self.dataset_stats)
 
                 if self.args.CyCADA:
-                    # TODO: implement CyCADA forward pass and loss computation
-                    # output = self.model(sample, train=True, alpha=0., return_features=False, padding=False)
-                    # loss += self.args.lam_cycada * self.cycada_loss(sample, output, self.model, self.args)
-                    pass
+                    # CyCADA forward pass and loss computation
+                    data = {"A": self.normalize(sample["S2"][sample["source"]]/4000), "B": self.normalize(sample["S2"][~sample["source"]]/4000), "A_paths": "", "B_paths": ""}
+                    self.CyCADAmodel.set_input(data)         # unpack data from dataset and apply preprocessing
+
+                    # Normalize S1
+                    sample_norm = apply_normalize(sample, self.dataset_stats)
+                    
+                    self.CyCADAmodel.S1_A = sample_norm["S1"][sample["source"]]
+                    self.CyCADAmodel.S1_B = sample_norm["S1"][~sample["source"]]
+                    self.CyCADAmodel.dataset_stats = self.dataset_stats
+                    self.CyCADAmodel.optimize_parameters(gt=sample["y"][sample["source"]])
+
+                    # replace all existing source domain samples with fake target domain samples
+                    sample["input"] = torch.cat([self.CyCADAmodel.fake_B_prep.detach(), self.CyCADAmodel.real_B_prep.detach()], dim=0)
+                    # sample = apply_transformations_and_normalize(sample, self.data_transform, self.dataset_stats)
+
+                else:
+                    sample = apply_transformations_and_normalize(sample, self.data_transform, self.dataset_stats)
                 
+                # forward pass for the main model
                 output = self.model(sample, train=True, alpha=self.info["alpha"] if self.args.adversarial else 0., return_features=self.args.da)
             
                 # compute loss
@@ -269,7 +297,22 @@ class Trainer:
                     loss += loss_raw * self.args.lam_raw
                     loss_dict_raw = detach_tensors_in_dict(loss_dict_raw)
                     # loss_dict = {**loss_dict, **loss_dict_raw}
-                
+
+                if self.args.CyCADA:
+
+                    # pixel supervision to the source domain model
+                    loss_targetconsistency = self.CyCADAmodel.criterionFakePop(output["popdensemap"][sample["source"]], self.CyCADAmodel.real_A_output["popdensemap"].detach())
+                    loss += loss_targetconsistency * self.args.lam_targetconsistency
+
+                    # implement selfsupervised loss
+
+                    # fake_output = self.model(sample, train=True, alpha=self.info["alpha"] if self.args.adversarial else 0., return_features=self.args.da)
+
+                    # target: self.CyCADAmodel.fake_A_output
+                    loss_selfsupervised_consitency = self.CyCADAmodel.criterionFakePop(output["popdensemap"][~sample["source"]], self.CyCADAmodel.fake_A_output["popdensemap"].detach())
+                    loss += loss_selfsupervised_consitency * self.args.lam_selfsupervised_consistency
+                    
+
                 # update loss
                 optim_loss += loss
 
@@ -290,6 +333,7 @@ class Trainer:
                 
                 # backprop and stuff
                 if self.info["epoch"] > 0 or not self.args.skip_first:
+                    # TODO: self.set_requires_grad([self.netD_A, self.netD_B], False)
                     optim_loss.backward()
 
                     # gradient clipping
@@ -317,6 +361,12 @@ class Trainer:
                     if self.dataloaders["weak_indices"][i%len(self.dataloaders["weak_indices"])] == self.dataloaders["weak_indices"][-1]:  
                         random.shuffle(self.dataloaders["weak_indices"]); self.log_train(); break
 
+                # if self.args.CyCADA:
+                #     if total_iters % opt.display_freq == 0:   # display images on visdom and save images to a HTML file
+                #         save_result = total_iters % opt.update_html_freq == 0
+                #         self.CyCADAmodel.compute_visuals()
+                #         self.visualizer.display_current_results(self.CyCADAmodel.get_current_visuals(), epoch, save_result)
+
                 # logging and stuff
                 if (i + 1) % min(self.args.logstep_train, len(self.dataloaders['train'])) == 0:
                     train_stats = self.log_train(train_stats,(inner_tnr, tnr))
@@ -434,13 +484,13 @@ class Trainer:
                 # Colellect predictions and samples
                 if full_eval:
                     pred.append(output["popcount"].view(-1)); gt.append(sample["y"].view(-1)) 
-                    loss, loss_dict = get_loss(output, sample, loss=args.loss, merge_aug=args.merge_aug, 
+                    _, loss_dict = get_loss(output, sample, loss=args.loss, merge_aug=args.merge_aug, 
                                                 lam_adv=args.lam_adv if self.args.adversarial else 0.0,
                                                 lam_coral=args.lam_coral if self.args.CORAL else 0.0,
                                                 lam_mmd=args.lam_mmd if self.args.MMD else 0.0,
                                                tag="test_main")
                     if self.boosted:
-                        loss_raw, loss_dict_raw = get_loss(output["intermediate"], sample, loss=args.loss, lam=args.lam, merge_aug=args.merge_aug,
+                        _, loss_dict_raw = get_loss(output["intermediate"], sample, loss=args.loss, lam=args.lam, merge_aug=args.merge_aug,
                                             lam_adv=args.lam_adv if self.args.adversarial else 0.0,
                                             lam_coral=args.lam_coral if self.args.CORAL else 0.0,
                                             lam_mmd=args.lam_mmd if self.args.MMD else 0.0,
@@ -526,11 +576,14 @@ class Trainer:
 
                 # inputialize the output map
                 h, w = testdataloader.dataset.shape()
-                output_map = torch.zeros((h, w))
-                output_map_var = torch.zeros((h, w))
-                output_map_count = torch.zeros((h, w))
-                output_map_raw = torch.zeros((h, w))
-                output_map_var_raw = torch.zeros((h, w))
+                output_map_count = torch.zeros((h, w), dtype=torch.int16)
+                output_map = torch.zeros((h, w), dtype=torch.float16)
+                if self.args.probabilistic:
+                    output_map_var = torch.zeros((h, w), dtype=torch.float16)
+                if self.boosted and full:
+                    output_map_raw = torch.zeros((h, w), dtype=torch.float16)
+                    if self.args.probabilistic:
+                        output_map_var_raw = torch.zeros((h, w), dtype=torch.float16)
 
                 for sample in tqdm(testdataloader, leave=False):
                     sample = to_cuda_inplace(sample)
@@ -544,23 +597,23 @@ class Trainer:
 
                     # get the output with a forward pass
                     output = self.model(sample, padding=False)
-                    output_map[xl:xl+ips, yl:yl+ips][mask.cpu()] += output["popdensemap"][0][mask].cpu()
+                    output_map[xl:xl+ips, yl:yl+ips][mask.cpu()] += output["popdensemap"][0][mask].cpu().to(torch.float16)
                     if self.args.probabilistic:
-                        output_map_var[xl:xl+ips, yl:yl+ips][mask.cpu()] += output["popvarmap"][0][mask].cpu()
+                        output_map_var[xl:xl+ips, yl:yl+ips][mask.cpu()] += output["popvarmap"][0][mask].cpu().to(torch.float16)
                     if self.boosted and full:
-                        output_map_raw[xl:xl+ips, yl:yl+ips][mask.cpu()] += output["intermediate"]["popdensemap"][0][mask].cpu()
+                        output_map_raw[xl:xl+ips, yl:yl+ips][mask.cpu()] += output["intermediate"]["popdensemap"][0][mask].cpu().to(torch.float16)
                         if self.args.probabilistic:
-                            output_map_var_raw[xl:xl+ips, yl:yl+ips][mask.cpu()] += output["intermediate"]["popvarmap"][0][mask].cpu()
+                            output_map_var_raw[xl:xl+ips, yl:yl+ips][mask.cpu()] += output["intermediate"]["popvarmap"][0][mask].cpu().to(torch.float16)
                     # output_map_count[xl:xl+ips, yl:yl+ips][mask.cpu()] += 1
 
                 # average over the number of times each pixel was visited
-                output_map[output_map_count>0] = output_map[output_map_count>0] / output_map_count[output_map_count>0]
-                if self.args.probabilistic:
-                    output_map_var[output_map_count>0] = output_map_var[output_map_count>0] / output_map_count[output_map_count>0]
-                if self.boosted:
-                    output_map_raw[output_map_count>0] = output_map_raw[output_map_count>0] / output_map_count[output_map_count>0]
-                    if self.args.probabilistic: 
-                        output_map_var_raw[output_map_count>0] = output_map_var_raw[output_map_count>0] / output_map_count[output_map_count>0]
+                # output_map[output_map_count>0] = output_map[output_map_count>0] / output_map_count[output_map_count>0]
+                # if self.args.probabilistic:
+                #     output_map_var[output_map_count>0] = output_map_var[output_map_count>0] / output_map_count[output_map_count>0]
+                # if self.boosted:
+                #     output_map_raw[output_map_count>0] = output_map_raw[output_map_count>0] / output_map_count[output_map_count>0]
+                #     if self.args.probabilistic: 
+                #         output_map_var_raw[output_map_count>0] = output_map_var_raw[output_map_count>0] / output_map_count[output_map_count>0]
 
                 if save:
                     # save the output map
@@ -628,10 +681,9 @@ class Trainer:
                     # HazeAdditionModule(p=0.5, atm_limit=(0.3, 1.0), haze_limit=(0.05,0.3))
         ]
         if args.eu2rwa:
-            S2augs.append(Eu2Rwa())
+            S2augs.append(Eu2Rwa(p=1.0))
         self.data_transform["S2"] = OwnCompose(S2augs)
 
-        
         self.data_transform["S1"] = transforms.Compose([
             # RandomBrightness(p=0.95),
             # RandomGamma(p=0.95),
@@ -697,7 +749,6 @@ class Trainer:
             "test_target":  [DataLoader(datasets["test_target"], batch_size=1, num_workers=1, shuffle=False, drop_last=False) for datasets["test_target"] in datasets["test_target"] ]
         }
         
-
         # add weakly supervised samples of the target domain to the trainind_dataset
         if args.supmode=="weaksup":
             # create the weakly supervised dataset stack them into a single dataset and dataloader
diff --git a/utils/__pycache__/losses.cpython-310.pyc b/utils/__pycache__/losses.cpython-310.pyc
index 07152f6..aee0c38 100644
Binary files a/utils/__pycache__/losses.cpython-310.pyc and b/utils/__pycache__/losses.cpython-310.pyc differ
diff --git a/utils/__pycache__/utils.cpython-310.pyc b/utils/__pycache__/utils.cpython-310.pyc
index a3998dd..ebd4e98 100644
Binary files a/utils/__pycache__/utils.cpython-310.pyc and b/utils/__pycache__/utils.cpython-310.pyc differ
diff --git a/utils/losses.py b/utils/losses.py
index 87f197f..9d06e68 100644
--- a/utils/losses.py
+++ b/utils/losses.py
@@ -140,7 +140,26 @@ def get_loss(output, gt, loss=["l1_loss"], lam=[1.0], merge_aug=False,
 
     return optimization_loss, auxdict
 
-        
+# def LogL1Loss(_Loss):
+#     """
+#     Log L1 loss
+#     """
+#     def __init__(self,* ):
+#         super(LogL1Loss, self).__init__(None, None,'mean')
+
+#     def forward(self, input: Tensor, target: Tensor) -> Tensor:
+#         return F.l1_loss(torch.log(input+1), torch.log(target+1))
+                         
+
+class LogL1Loss(_Loss):
+
+    def __init__(self, *, full: bool = False, reduction: str = 'mean') -> None:
+        super(LogL1Loss, self).__init__(None, None, reduction)
+
+    def forward(self, pred: Tensor, var:Tensor, target: Tensor) -> Tensor:
+        return F.l1_loss(torch.log(input+1), torch.log(target+1))
+    
+
 class LaplacianNLLLoss(_Loss):
     """Laplacian negative log-likelihood loss using log-variance
 
diff --git a/utils/plot.py b/utils/plot.py
index 5931bd3..0da5d55 100644
--- a/utils/plot.py
+++ b/utils/plot.py
@@ -127,6 +127,8 @@ def scatter_plot2(predicted, ground_truth):
 
 import numpy as np
 import matplotlib.pyplot as plt
+import matplotlib
+matplotlib.use('Agg')
 from scipy.stats import gaussian_kde
 
 def scatter_plot3(predicted, ground_truth):
diff --git a/utils/utils.py b/utils/utils.py
index a86f409..ed2874b 100644
--- a/utils/utils.py
+++ b/utils/utils.py
@@ -243,6 +243,12 @@ def load_json(file):
         a = json.load(f)
     return a
 
+def single_normalize(data, stat):
+    """
+    nomalize th data witht the given statistics
+
+    """
+
 
 def apply_normalize(indata, dataset_stats):
 
@@ -250,7 +256,7 @@ def apply_normalize(indata, dataset_stats):
     if "S2" in indata:
         if indata["S2"].shape[0] == 4:
             # indata["S2"] = torch.where(indata["S2"] > self.dataset_stats["sen2springNIR"]['p2'][:,None,None], self.dataset_stats["sen2springNIR"]['p2'][:,None,None], indata["S2"])
-            indata["S2"] = ((indata["S2"].permute((0,2,3,1)) - dataset_stats["sen2springNIR"]['mean'] ) / dataset_stats["sen2springNIR"]['std']).permute((0,3,1,2))
+            indata["S2"] = ((indata["S2"].permute((0,2,3,1)) - dataset_stats["sen2springNIR"]['mean'].cuda() ) / dataset_stats["sen2springNIR"]['std'].cuda()).permute((0,3,1,2))
         else: 
             # indata["S2"] = torch.where(indata["S2"] > self.dataset_stats["sen2spring"]['p2'][:,None,None], self.dataset_stats["sen2spring"]['p2'][:,None,None], indata["S2"])
             # indata["S2"] = ((indata["S2"].permute((1,2,0)) - dataset_stats["sen2spring"]['mean'] ) / dataset_stats["sen2spring"]['std']).permute((2,0,1))
